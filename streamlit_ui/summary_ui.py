import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import BiliBiliLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_community.vectorstores import Chroma
from fastapi import HTTPException
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# bilibiliå·¥å…·ç±»
class BiliBiliTool:
    def __init__(self) -> None:
        # åˆå§‹åŒ–llmï¼ˆè¯­è¨€æ¨¡å‹ï¼‰
        self._llm = ChatOpenAI(model=openai_model, openai_api_key=openai_api_key, openai_api_base=openai_api_base, max_tokens=1024, temperature=0, streaming=True)
        # åˆå§‹åŒ–embeddingsï¼ˆåµŒå…¥æ¨¡å‹ï¼‰
        self._embedding_model = HuggingFaceEmbeddings(model_name=embedings_path, model_kwargs={'device': f'{embedings_device}'})
        self._sessdata = sessdata
        self._buvid3 = buvid3
        self._bili_jct = bili_jct
        # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
        self._text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)

    # åˆ‡å‰²bilibili docsï¼ˆæ–‡æ¡£ï¼‰
    def _split_docs(self, docs):
        # åˆæ­¥åˆ†å‰²æ–‡æ¡£
        document = self._text_splitter.split_documents(docs)
        # è¿‡æ»¤å¤æ‚metadataï¼ˆå…ƒæ•°æ®ï¼‰
        return filter_complex_metadata(documents=document)

    # è·å–bvå·è¯¦ç»†ä¿¡æ¯
    def _get_bv_docs(self, bv_id):
        # æ ¹æ®bvå·åŠ è½½bilibiliè§†é¢‘ä¿¡æ¯
        loader = BiliBiliLoader([f"https://www.bilibili.com/video/{bv_id}"], sessdata=self._sessdata, bili_jct=self._bili_jct, buvid3=self._buvid3)
        docs = loader.load()
        #åˆ¤æ–­å­—å¹•å†…å®¹æ˜¯å¦ä¸ºç©º
        if docs[0].__dict__['page_content'] =='':
            st.error("No subtitles found for video")
        # åˆ‡å‰²å¹¶å¤„ç†æ–‡æ¡£
        pure_doc = self._split_docs(docs=docs)
        return pure_doc
    def _format_docs(self,docs):
        return "\n\n".join(doc.page_content for doc in docs)
    # æ€»ç»“è§†é¢‘å†…å®¹
    def get_video_summary(self, bv_id, prompt: str = None,stream: bool = False):
        # è·å–å¤„ç†åçš„è§†é¢‘æ–‡æ¡£
        docs = self._get_bv_docs(bv_id)
        RAG_TEMPLATE = """
            You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
            <context>
            {context}
            </context>
            Answer the following question:
            {question}
        """

        rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)

        chain = (RunnablePassthrough.assign(context=lambda input: self._format_docs(input["context"]))
            | rag_prompt
            | self._llm
            | StrOutputParser()
        )
        if stream:
            gen = chain.stream({"context": docs, "question": prompt})
            return gen
        ans = chain.invoke({"context": docs, "question":  prompt})
        try:
            ans_dict = docs["context"][0].__dict__
            # æ„å»ºå“åº”æ•°æ®
            resp = {
                "avid": ans_dict['metadata']['aid'],
                "bvid": ans_dict['metadata']['bvid'],
                "cid": ans_dict['metadata']['cid'],
                "title": ans_dict['metadata']['title'],
                "url": ans_dict['metadata']['url'],
                "answer": ans
            }
        except Exception as e:
            # å¼‚å¸¸å¤„ç†ï¼šè¿”å›HTTP 500é”™è¯¯
            raise HTTPException(status_code=500, detail=str(e))
        return resp

st.set_page_config(page_title="ğŸ’¬ BiliBili Summary")
#æ£€æŸ¥å‚æ•°æ˜¯å¦å¡«å……
def check_params(params:dict) -> bool:
    for key in params:
        if params[key] == "":
            return False
    return True

st.sidebar.title("Parameter setting")
st.sidebar.text("Bç«™ç›¸å…³å‚æ•°è®¾ç½®:")
sessdata = st.sidebar.text_input(label="SESSDATA",type="password")
buvid3 = st.sidebar.text_input(label="BVID3",type="password")
bili_jct = st.sidebar.text_input(label="BILI_JCT",type="password")

st.sidebar.text("Openai API ç›¸å…³å‚æ•°è®¾ç½®:")
openai_model = st.sidebar.text_input(label="Openai Model")
openai_api_key = st.sidebar.text_input(label="Openai API Key",type="password")
openai_api_base = st.sidebar.text_input(label="Openai API Base")

st.sidebar.text("Embedings Modelç›¸å…³å‚æ•°è®¾ç½®:")
embedings_path = st.sidebar.text_input(label="Embedings Model Absolute Path")
embedings_device = st.sidebar.selectbox(label="Embedings Device",options=['cuda','cpu',"mps", "npu"])

st.sidebar.text("æ–‡æœ¬åˆ†å‰²å™¨å‚æ•°è®¾ç½®:")
chunk_size = int(st.sidebar.text_input(label="chunk_size",value=1000))
chunk_overlap =int(st.sidebar.text_input(label="chunk_overlap",value=20))

st.sidebar.text("è‡ªå®šä¹‰æé—®Promptå‚æ•°è®¾ç½®(å¯é€‰):")
prompt = st.sidebar.text_area(label="Prompt",value="""è¯·æ ¹æ®è§†é¢‘å†…å®¹æç‚¼å¹¶æ€»ç»“ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š
1. è§†é¢‘çš„æ ¸å¿ƒè§‚ç‚¹æˆ–è®ºè¿°ï¼ˆæ¦‚è¿°è§†é¢‘æ‰€ä¼ è¾¾çš„ä¸»è¦æ€æƒ³æˆ–ç«‹åœºï¼‰,
2. å…³é”®äººç‰©æˆ–äº‹ä»¶ï¼ˆçªå‡ºè§†é¢‘ä¸­æ¶‰åŠçš„é‡è¦è§’è‰²æˆ–äº‹ä»¶ï¼‰,
3. è§†é¢‘çš„ä¸»çº¿å†…å®¹ï¼ˆæ¢³ç†è§†é¢‘çš„æ•´ä½“é€»è¾‘å’Œå‘å±•è„‰ç»œï¼Œé‡ç‚¹æè¿°é‡è¦çš„æƒ…èŠ‚æˆ–è®¨è®ºçš„ä¸»é¢˜ï¼‰,
4.åœ¨æ€»ç»“çš„æœ€åï¼Œæä¾›ä½ ä¸ªäººå¯¹è§†é¢‘å†…å®¹çš„çœ‹æ³•ï¼ŒåŒ…æ‹¬ä½ çš„è¯„ä»·ã€æ”¯æŒæˆ–è´¨ç–‘çš„åŸå› ï¼Œå¹¶ç®€è¦è§£é‡Šä¸ºä½•æŒæœ‰æ­¤è§‚ç‚¹ã€‚
è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
æ ¸å¿ƒè§‚ç‚¹ï¼š
å…³é”®äººç‰©/äº‹ä»¶ï¼š
ä¸»çº¿å†…å®¹ï¼š
ä¸ªäººçœ‹æ³•ï¼š
 """,height=450)

st.title("BiliBili Summary")

params = {
    "sessdata":sessdata,
    "buvid3":buvid3,
    "bili_jct":bili_jct,
    "openai_model":openai_model,
    "openai_api_key":openai_api_key,
    "openai_api_base":openai_api_base,
    "embedings_path":embedings_path,
}

if check_params(params):
    bt = BiliBiliTool()
else:
    st.error("å‚æ•°æœªè®¾ç½®ï¼Œè¯·å…ˆè®¾ç½®å‚æ•°")
    st.stop()

if bv_id := st.text_input(label="bvå·"):
    if st.button(label="å¼€å§‹æ€»ç»“"):
        gen = bt.get_video_summary(bv_id,prompt=prompt,stream=True)
        st.write_stream(gen)
        if st.button(label="æ¸…ç©º"):
            bv_id = None
